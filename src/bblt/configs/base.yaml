model_name: Qwen/Qwen2.5-0.5B
max_length: 512

seed: 42
device_map: auto

# training defaults (used by train configs)
train:
  per_device_batch_size: 4
  grad_accum_steps: 4
  lr: 2.0e-4
  epochs: 3
  warmup_ratio: 0.03
  weight_decay: 0.0
  max_train_examples: null   # null = full
  eval_split: validation     

lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["q_proj", "v_proj"]
